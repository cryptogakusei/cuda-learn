{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/YellowLabradorLooking_new.jpg/1200px-YellowLabradorLooking_new.jpg'\n",
    "# url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Cute_dog.jpg/1600px-Cute_dog.jpg?20140729055059'\n",
    "url = 'https://github.com/gpu-mode/lectures/blob/main/lecture_003/puppy.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, math, gzip, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "\n",
    "from torch import tensor\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.functional as tvf\n",
    "from torchvision import io\n",
    "from torch.utils.cpp_extension import load_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d538d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_image = Path('puppy.jpg')\n",
    "# if not path_image.exists():\n",
    "#     response = requests.get(url)\n",
    "#     with open(path_image, 'wb') as f:\n",
    "#         f.write(response.content)\n",
    "#     print('Downloaded!')\n",
    "\n",
    "path_img = Path('puppy.jpg')\n",
    "if not path_img.exists(): urlretrieve(url, path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.getsize('puppy.jpg'), 'bytes')\n",
    "\n",
    "# Check the first few bytes\n",
    "with open('puppy.jpg', 'rb') as f:\n",
    "    print(f.read(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.read_image('puppy.jpg')\n",
    "print(img.shape)\n",
    "img[:2, :3, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(x, figsize=(4,3), **kwargs):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    if len(x.shape)==3: x = x.permute(1, 2, 0)\n",
    "    plt.imshow(x.cpu(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e19c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = tvf.resize(img, 150, antialias=True)\n",
    "ch, h, w = img2.shape\n",
    "ch, h, w, h*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd060063",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(x):\n",
    "    c, h, w = x.shape\n",
    "    n = h*w\n",
    "    x = x.flatten()\n",
    "    res = torch.empty(n, dtype=x.dtype, device=x.device)\n",
    "    for i in range(n): res[i] = 0.2989*x[i] + 0.5870*x[i+n] + 0.1140*x[i+2*n]\n",
    "    return res.view(h, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247027d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_rgb = rgb2gray(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fa969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel(f, blocks, threads, *args):\n",
    "    for i in range(blocks):\n",
    "        for j in range(threads): f(i, j, threads, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e477fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray_bk(blockidx, threadidx, blockdim, x, out, n):\n",
    "    i = blockidx*blockdim + threadidx\n",
    "    if i<n: out[i] =  0.2989*x[i] + 0.5870*x[i+n] + 0.1140*x[i+2*n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead09af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray_pybk(x):\n",
    "    c, h, w = x.shape\n",
    "    n = h*w\n",
    "    x = x.flatten()\n",
    "    res = torch.empty(n, dtype=x.dtype, device=x.device)\n",
    "    threads = 256\n",
    "    blocks = int(math.ceil(h*w/threads))\n",
    "    blk_kernel(rgb2gray_bk, blocks, threads, x, res, n)\n",
    "    return res.view(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = rgb2gray_pybk(img2)\n",
    "show_img(img_g, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']='1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beaf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q wurlitzer ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be386b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybind11\n",
    "print(pybind11.get_include())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f000b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
    "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs, extra_include_paths=[pybind11.get_include()],\n",
    "                       extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=\"inline_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return ( a + b - 1) / b;}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void rgb_to_grayscale_kernel(unsigned char* x, unsigned char* out, int n) {\n",
    "    int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    if (i<n) out[i] = 0.2989*x[i] + 0.5870*x[i+n] + 0.1140*x[i+2*n];\n",
    "}\n",
    "\n",
    "torch::Tensor rgb_to_grayscale(torch::Tensor input) {\n",
    "    CHECK_INPUT(input);\n",
    "    int h = input.size(1);\n",
    "    int w = input.size(2);\n",
    "    printf(\"h*w: %d%d\\n\", h, w);\n",
    "    auto output = torch::empty({h,w}, input.options());\n",
    "    int threads = 256;\n",
    "    rgb_to_grayscale_kernel<<<cdiv(w*h, threads), threads>>>(\n",
    "        input.data_ptr<unsigned char>(), output.data_ptr<unsigned char>(), w*h);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21986054",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_src = \"torch::Tensor rgb_to_grayscale(torch::Tensor input);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, ['rgb_to_grayscale'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df21e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc = img.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = module.rgb_to_grayscale(imgc).cpu()\n",
    "h,w = res.shape\n",
    "h,w,h*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db85403",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(res, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d344ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d123d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL = 'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ecc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train.shape, x_train.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "weights = torch.randn(784, 10)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace as ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d(f, blocks, threads, *args):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            for j0 in range(threads.y):\n",
    "                for j1 in range(threads.x): f(ns(y=i0,x=i1), ns(y=j0,x=j1), threads, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_bk(blockIdx, threadIdx, blockDim, m ,n, out, h, w, k):\n",
    "    r = blockIdx.y*blockDim.y + threadIdx.y\n",
    "    c = blockIdx.x*blockDim.x + threadIdx.x\n",
    "\n",
    "    if (r >= h or c >= w): return\n",
    "    o = 0\n",
    "    for i in range(k): o += m[r*k + i] * n[i*w + c]\n",
    "    out[r*w + c] = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n):\n",
    "    h,k = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"size mismatch\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = ns(x=16,y=16)\n",
    "    blocks = ns(x=math.ceil(w/tpb.x), y=math.ceil(h/tpb.y))\n",
    "    blk_kernel2d(matmul_bk, blocks, tpb, \n",
    "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.randn(500, 200, device=\"cuda\")\n",
    "m2 = torch.randn(200, 1000, device=\"cuda\")\n",
    "# res = matmul_2d(m1, m2)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void matmul_k(float* m, float* n, float* out, int h, int k, int w) {\n",
    "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (r>=h || c>=w) return;\n",
    "    float o = 0;\n",
    "    for(int i=0; i < k; i++) o += m[r*k+i]*n[i*w+c];\n",
    "    out[r*w+c] = o;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h,w}, m.options());\n",
    "\n",
    "    dim3 tpb(16,16);\n",
    "    dim3 blocks(cdiv(w,tpb.x), cdiv(h, tpb.y));\n",
    "    matmul_k<<<blocks, tpb>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ef2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_src = \"torch::Tensor matmul(torch::Tensor m, torch::Tensor n);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, ['matmul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c, m2c = m1.contiguous().cuda(), m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81443fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time module.matmul(m1,m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.max_threads_per_multi_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce54276",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "constexpr int TILE_SIZE = 16;\n",
    "\n",
    "__global__ void tiled_matmul_kernel(float* out, float* M, float*N, int h, int w, int k) {\n",
    "    __shared__ float Ms[TILE_SIZE][TILE_SIZE];\n",
    "    __shared__ float Ns[TILE_SIZE][TILE_SIZE];\n",
    "\n",
    "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    float res = 0.0f;\n",
    "\n",
    "    for (int K_tileidx = 0; K_tileidx < (k + TILE_SIZE - 1)/TILE_SIZE; K_tileidx++) {\n",
    "        Ms[threadIdx.y][threadIdx.x] = (((r < h) && (K_tileidx*TILE_SIZE + threadIdx.x < k)) ? M[r*k + (K_tileidx*TILE_SIZE + threadIdx.x)]: 0.0f);\n",
    "        Ns[threadIdx.y][threadIdx.x] = (((K_tileidx*TILE_SIZE + threadIdx.y < k) && (c < w)) ? N[(K_tileidx*TILE_SIZE + threadIdx.y)*w + c]: 0.0f);\n",
    "        __syncthreads(); // all the tile is filled after this as all threads in the tile has finished work\n",
    "\n",
    "        for (int idx=0; idx < TILE_SIZE; idx++) {\n",
    "            res += Ms[threadIdx.y][idx] * Ns[idx][threadIdx.x];\n",
    "        }\n",
    "        __syncthreads(); // wait for all the threads in the tile to finish work on the shared mem\n",
    "\n",
    "    }\n",
    "\n",
    "    if ((r<h) && (c<w)) {\n",
    "        out[r*w + c] = res;\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor titled_matmul(const torch::Tensor& m, const torch::Tensor& n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"size mismatch\");\n",
    "    auto output = torch::empty({h,w}, m.options());\n",
    "\n",
    "    dim3 tpb(TILE_SIZE, TILE_SIZE);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "    tiled_matmul_kernel<<<blocks, tpb>>>(output.data_ptr<float>(), m.data_ptr<float>(), n.data_ptr<float>(), h, w, k);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_src = \"\"\"\n",
    "torch::Tensor titled_matmul(const torch::Tensor& m, const torch::Tensor& n);\n",
    "\"\"\"\n",
    "titled_matmul_module = load_cuda(cuda_src, cpp_src, ['titled_matmul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(titled_matmul_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c387be",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.randn(500, 200, device=\"cuda\")\n",
    "bb = torch.randn(200, 1000, device=\"cuda\")\n",
    "\n",
    "%timeit titled_matmul_module.titled_matmul(aa, bb)\n",
    "\n",
    "%timeit aa@bb\n",
    "\n",
    "(titled_matmul_module.titled_matmul(aa, bb) - aa@bb).abs().max()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
